---
layout: false
---
<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Factory Architecture</title>
    <style>
        /* CSS Variables - Cisco Inspired Palette */
        :root {
            --cisco-navy: #00223A;
            --cisco-blue: #00BCEB;
            --cisco-light-blue: #E8F2F5;
            --cisco-gray-900: #1E293B;
            --cisco-gray-700: #334155;
            --cisco-gray-500: #64748B;
            --cisco-gray-200: #E2E8F0;
            --cisco-bg: #F8FAFC;
            --white: #FFFFFF;
            --card-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            --hover-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            --transition-speed: 0.3s;
        }

        /* Reset & Typography */
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: var(--cisco-bg);
            color: var(--cisco-gray-900);
            line-height: 1.6;
            -webkit-font-smoothing: antialiased;
        }

        /* Layout */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        /* Header */
        header {
            background-color: var(--cisco-navy);
            color: var(--white);
            padding: 2rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            position: relative;
            box-shadow: var(--card-shadow);
        }

        .header-content {
            max-width: 800px;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .subtitle {
            font-size: 1.2rem;
            color: var(--cisco-blue);
            margin-bottom: 1.5rem;
        }

        .analogy-box {
            background: rgba(255, 255, 255, 0.1);
            padding: 1.5rem;
            border-left: 4px solid var(--cisco-blue);
            border-radius: 4px;
            font-size: 0.95rem;
        }

        /* Language Toggle */
        .lang-toggle {
            position: absolute;
            top: 2rem;
            right: 2rem;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--white);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            cursor: pointer;
            font-weight: 600;
            transition: all var(--transition-speed) ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .lang-toggle:hover {
            background: var(--cisco-blue);
            border-color: var(--cisco-blue);
        }

        /* Layer Architectures */
        .layers-container {
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
        }

        .layer {
            background: var(--white);
            border-radius: 12px;
            box-shadow: var(--card-shadow);
            overflow: hidden;
            transition: all var(--transition-speed) ease;
            border: 1px solid var(--cisco-gray-200);
        }

        .layer-header {
            padding: 1.5rem 2rem;
            display: flex;
            align-items: center;
            cursor: pointer;
            background: var(--white);
            border-bottom: 1px solid transparent;
            transition: background var(--transition-speed) ease;
        }

        .layer-header:hover {
            background: var(--cisco-light-blue);
        }

        .layer.active .layer-header {
            border-bottom: 1px solid var(--cisco-gray-200);
            background: var(--cisco-light-blue);
        }

        .layer-icon {
            width: 48px;
            height: 48px;
            background: var(--cisco-blue);
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 1.5rem;
            flex-shrink: 0;
        }

        .layer-icon svg {
            width: 24px;
            height: 24px;
            fill: var(--white);
        }

        .layer-title-wrapper {
            flex-grow: 1;
        }

        .layer-title {
            font-size: 1.25rem;
            font-weight: 700;
            color: var(--cisco-navy);
            margin-bottom: 0.25rem;
        }

        .layer-desc {
            font-size: 0.9rem;
            color: var(--cisco-gray-500);
        }

        .expand-icon {
            width: 24px;
            height: 24px;
            fill: var(--cisco-gray-500);
            transition: transform var(--transition-speed) ease;
        }

        .layer.active .expand-icon {
            transform: rotate(180deg);
        }

        /* Layer Content & Tech Cards */
        .layer-content {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 1.5rem;
            padding: 0;
            max-height: 0;
            opacity: 0;
            overflow: hidden;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .layer.active .layer-content {
            padding: 2rem;
            max-height: 2000px; /* Arbitrary large number to allow expansion */
            opacity: 1;
        }

        .tech-card {
            background: var(--white);
            border: 1px solid var(--cisco-gray-200);
            border-radius: 8px;
            padding: 1.5rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
            transition: transform var(--transition-speed) ease, box-shadow var(--transition-speed) ease;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .tech-card:hover {
            transform: translateY(-4px);
            box-shadow: var(--hover-shadow);
            border-color: var(--cisco-blue);
        }

        .tech-name {
            font-size: 1.15rem;
            font-weight: 700;
            color: var(--cisco-navy);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .tech-name::before {
            content: '';
            display: block;
            width: 4px;
            height: 1.15rem;
            background-color: var(--cisco-blue);
            border-radius: 2px;
        }

        .golden-circle {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }

        .gc-item {
            font-size: 0.9rem;
        }

        .gc-label {
            font-weight: 700;
            text-transform: uppercase;
            font-size: 0.75rem;
            letter-spacing: 0.05em;
            display: inline-block;
            padding: 2px 6px;
            border-radius: 4px;
            margin-right: 0.5rem;
            margin-bottom: 0.25rem;
        }

        .gc-what .gc-label { background: #E0E7FF; color: #3730A3; }
        .gc-why .gc-label { background: #FEF3C7; color: #92400E; }
        .gc-how .gc-label { background: #D1FAE5; color: #065F46; }

        .gc-text {
            color: var(--cisco-gray-700);
            display: block;
            margin-top: 2px;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .container { padding: 1rem; }
            h1 { font-size: 1.8rem; }
            .header-content { margin-top: 2.5rem; }
            .lang-toggle { top: 1rem; right: 1rem; }
            .layer-header { padding: 1.25rem 1rem; }
            .layer-icon { width: 40px; height: 40px; margin-right: 1rem; }
            .layer.active .layer-content { padding: 1.5rem 1rem; }
            .tech-card { padding: 1.25rem; }
        }
    </style>
</head>
<body>

    <div class="container">
        <header>
            <button class="lang-toggle" id="langToggle" onclick="toggleLanguage()">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                <span id="langBtnText">EN</span>
            </button>
            <div class="header-content">
                <h1 data-i18n="headerTitle">AIå·¥å‚æ¶æ„å…¨æ™¯å›¾</h1>
                <div class="subtitle" data-i18n="headerSubtitle">è§£å¯†ç°ä»£AIåŸºç¡€è®¾æ–½ï¼šä»åº•å±‚ç¡¬ä»¶åˆ°ä¸Šå±‚åº”ç”¨çš„ç«¯åˆ°ç«¯è§£æ</div>
                <div class="analogy-box">
                    <strong data-i18n="analogyTitle">ğŸ’¡ æ ¸å¿ƒéšå–»ï¼šç”Ÿäº§æ™ºèƒ½çš„è¶…çº§ç°ä»£å·¥å‚</strong><br>
                    <span data-i18n="analogyText">
                        è¦ç†è§£å¤æ‚çš„AIç”Ÿæ€ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æƒ³è±¡ä¸ºä¸€ä¸ªè¶…çº§å·¥å‚ï¼š<br>
                        â€¢ <strong>æ•°æ®</strong> æ˜¯åŸææ–™<br>
                        â€¢ <strong>GPU</strong> æ˜¯æµæ°´çº¿å·¥äºº<br>
                        â€¢ <strong>ç½‘ç»œ</strong> æ˜¯ä¼ é€å¸¦<br>
                        â€¢ <strong>AIåº”ç”¨</strong> æ˜¯æœ€ç»ˆäº§å‡ºçš„å®šåˆ¶å•†å“
                    </span>
                </div>
            </div>
        </header>

        <div class="layers-container" id="layersContainer">
            <!-- Content will be injected by JavaScript -->
        </div>
    </div>

    <script>
        // Data Structure utilizing the Feynman Technique and Golden Circle
        const data = {
            zh: {
                headerTitle: "AIå·¥å‚æ¶æ„å…¨æ™¯å›¾",
                headerSubtitle: "è§£å¯†ç°ä»£AIåŸºç¡€è®¾æ–½ï¼šä»åº•å±‚ç¡¬ä»¶åˆ°ä¸Šå±‚åº”ç”¨çš„ç«¯åˆ°ç«¯è§£æ",
                analogyTitle: "ğŸ’¡ æ ¸å¿ƒéšå–»ï¼šç”Ÿäº§æ™ºèƒ½çš„è¶…çº§ç°ä»£å·¥å‚",
                analogyText: "è¦ç†è§£å¤æ‚çš„AIç”Ÿæ€ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æƒ³è±¡ä¸ºä¸€ä¸ªè¶…çº§å·¥å‚ï¼š<br>â€¢ <strong>æ•°æ®</strong> æ˜¯åŸææ–™<br>â€¢ <strong>GPU</strong> æ˜¯æµæ°´çº¿å·¥äºº<br>â€¢ <strong>ç½‘ç»œ</strong> æ˜¯é«˜é€Ÿä¼ é€å¸¦<br>â€¢ <strong>AIåº”ç”¨</strong> æ˜¯æœ€ç»ˆäº§å‡ºçš„é«˜ä»·å€¼å®šåˆ¶å•†å“",
                labels: { what: "æ˜¯ä»€ä¹ˆ (What)", why: "ä¸ºä»€ä¹ˆ (Why)", how: "å¦‚ä½•å®ç° (How)" },
                layers: [
                    {
                        id: "layer1",
                        icon: `<path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"/>`, // Stack icon
                        title: "ç¬¬ä¸€å±‚ï¼šAI åº”ç”¨ä¸ä¸šåŠ¡å±‚ (Application Layer)",
                        desc: "å·¥å‚çš„äº¤ä»˜çª—å£â€”â€”ç›´æ¥ä¸ºç»ˆç«¯ç”¨æˆ·æä¾›ä¸šåŠ¡ä»·å€¼",
                        items: [
                            {
                                name: "å¤§è¯­è¨€æ¨¡å‹ (LLM / Llama 3 / GPT)",
                                what: "å…·å¤‡ç™¾äº¿/åƒäº¿çº§å‚æ•°çš„äººå·¥æ™ºèƒ½åŸºç¡€æ¨¡å‹ã€‚",
                                why: "ä¼ ç»Ÿè½¯ä»¶åŸºäºå›ºå®šè§„åˆ™ï¼Œè€ŒLLMé€šè¿‡ç†è§£è‡ªç„¶è¯­è¨€ï¼Œèƒ½å¤Ÿæ‰§è¡Œæ¨ç†ã€ç¼–ç¨‹ã€åˆ›ä½œç­‰å¤æ‚æ³›åŒ–ä»»åŠ¡ã€‚",
                                how: "é€šè¿‡é¢„è®­ç»ƒï¼ˆé˜…è¯»æµ·é‡äº’è”ç½‘æ•°æ®å»ºç«‹è¯­è¨€ç¥ç»è¿æ¥ï¼‰å’Œå¾®è°ƒï¼ˆå¯¹é½äººç±»åå¥½ï¼‰ï¼Œåˆ©ç”¨Transformeræ¶æ„é¢„æµ‹ä¸‹ä¸€ä¸ªTokenã€‚"
                            },
                            {
                                name: "RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)",
                                what: "ä¸€ç§å°†ä¼ä¸šç§æœ‰çŸ¥è¯†åº“ä¸å¤§æ¨¡å‹èƒ½åŠ›ç»“åˆçš„åº”ç”¨èŒƒå¼ã€‚",
                                why: "å¤§æ¨¡å‹çš„çŸ¥è¯†åœç•™åœ¨è®­ç»ƒæˆªæ­¢æ—¥ï¼Œä¸”ä¼šäº§ç”Ÿâ€œå¹»è§‰â€ã€‚ä¼ä¸šéœ€è¦åŸºäºæœ€æ–°ã€ç»å¯¹å‡†ç¡®çš„ç§æœ‰æ•°æ®æ¥ç”Ÿæˆå›ç­”ã€‚",
                                how: "å½“ç”¨æˆ·æé—®æ—¶ï¼Œç³»ç»Ÿå…ˆåœ¨ç§æœ‰æ•°æ®åº“ä¸­æ£€ç´¢å‡ºç›¸å…³æ–‡æ¡£ï¼ˆçŸ¥è¯†ï¼‰ï¼Œç„¶åå°†â€œé—®é¢˜+æ–‡æ¡£â€ä¸€èµ·æ‰“åŒ…å–‚ç»™å¤§æ¨¡å‹ï¼Œè®©å…¶åŸºäºç»™å®šäº‹å®è¿›è¡Œæ€»ç»“ç”Ÿæˆã€‚"
                            },
                            {
                                name: "Agentic AI (æ™ºèƒ½ä½“)",
                                what: "å…·å¤‡è‡ªä¸»è§„åˆ’ã€å·¥å…·è°ƒç”¨å’Œå¤šæ­¥å†³ç­–èƒ½åŠ›çš„AIç³»ç»Ÿã€‚",
                                why: "çªç ´LLMåªèƒ½â€œé™ªèŠâ€çš„é™åˆ¶ï¼Œä½¿å…¶æˆä¸ºèƒ½ä»£æ›¿äººç±»æ‰§è¡ŒçœŸå®ä¸–ç•Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚è®¢ç¥¨ã€æŸ¥åº“ã€æ“ä½œè½¯ä»¶ï¼‰çš„æ•°å­—å‘˜å·¥ã€‚",
                                how: "ä¸ºå¤§æ¨¡å‹é…å¤‡â€œå¤§è„‘ï¼ˆè®°å¿†ä¸è§„åˆ’å¼•æ“ï¼‰â€å’Œâ€œæ‰‹è„šï¼ˆAPI/å·¥å…·ç®±ï¼‰â€ã€‚æ¨¡å‹è‡ªä¸»åˆ†æä»»åŠ¡æ­¥éª¤ï¼ŒæŒ‰éœ€æ‰§è¡ŒSQLä»£ç æˆ–ç½‘é¡µæœç´¢ï¼Œæœ€åæ±‡æ€»ç»“æœã€‚"
                            }
                        ]
                    },
                    {
                        id: "layer2",
                        icon: `<path d="M12 15c-1.66 0-3-1.34-3-3s1.34-3 3-3 3 1.34 3 3-1.34 3-3 3zm0-8c-2.76 0-5 2.24-5 5s2.24 5 5 5 5-2.24 5-5-2.24-5-5-5zm8.56 3.44c.22-.66.34-1.36.34-2.09 0-3.53-2.61-6.43-6-6.92V.43C19.12.96 22 4.13 22 7.85c0 .92-.17 1.8-.48 2.61l-1.96-1.02zM1.96 11.02C1.74 11.68 1.62 12.38 1.62 13.1c0 3.53 2.61 6.43 6 6.92v1.01c-4.23-.53-7.11-3.7-7.11-7.42 0-.92.17-1.8.48-2.61l1.97 1.02z"/>`, // Orchestration/Gears
                        title: "ç¬¬äºŒå±‚ï¼šæ¨¡å‹ç¼–æ’ä¸æ¨ç†æœåŠ¡å±‚ (Orchestration & Serving Layer)",
                        desc: "å·¥å‚çš„è½¦é—´è°ƒåº¦â€”â€”é«˜æ•ˆç®¡ç†ç®—åŠ›å¹¶æä¾›æ ‡å‡†åŒ–æœåŠ¡",
                        items: [
                            {
                                name: "Kubernetes (K8s)",
                                what: "å¼€æºçš„å®¹å™¨ç¼–æ’ä¸é›†ç¾¤ç®¡ç†æ“ä½œç³»ç»Ÿã€‚",
                                why: "AIä»»åŠ¡æå…¶åºå¤§ä¸”ç»„ä»¶ç¹å¤šï¼Œæ‰‹åŠ¨ç®¡ç†æˆç™¾ä¸Šåƒå°æœåŠ¡å™¨ä¸Šçš„ç¯å¢ƒé…ç½®ä¼šå¯¼è‡´ç¾éš¾ã€‚éœ€è¦è‡ªåŠ¨åŒ–çš„éƒ¨ç½²ã€æ‰©å±•å’Œè‡ªæ„ˆæœºåˆ¶ã€‚",
                                how: "å°†åº”ç”¨æ‰“åŒ…æˆå®¹å™¨ï¼ˆè½»é‡çº§éš”ç¦»ç¯å¢ƒï¼‰ï¼ŒK8sä½œä¸ºâ€œæ•°æ®ä¸­å¿ƒæ“ä½œç³»ç»Ÿâ€ï¼Œæ™ºèƒ½åœ°å°†è¿™äº›å®¹å™¨è°ƒåº¦åˆ°åˆé€‚çš„æœåŠ¡å™¨èŠ‚ç‚¹ä¸Šè¿è¡Œå¹¶ç›‘æ§å…¶çŠ¶æ€ã€‚"
                            },
                            {
                                name: "NVIDIA Run:ai",
                                what: "æ„å»ºåœ¨K8sä¹‹ä¸Šçš„AIä¸“ç”¨é«˜çº§ç®—åŠ›è°ƒåº¦å™¨ã€‚",
                                why: "GPUæå…¶æ˜‚è´µä½†åˆ©ç”¨ç‡å¾€å¾€å¾ˆä½ï¼ˆå¸¸è¢«é—²ç½®æˆ–ç‹¬å ï¼‰ã€‚ä¼ä¸šéœ€è¦è®©å¤šä¸ªæ•°æ®ç§‘å­¦å›¢é˜Ÿåƒä½¿ç”¨æ°´å¢¨ä¸€æ ·å…±äº«ç®—åŠ›æ± ã€‚",
                                how: "é€šè¿‡åŠ¨æ€é…é¢ã€ä»»åŠ¡æ’é˜Ÿæœºåˆ¶ä»¥åŠâ€œåˆ‡åˆ†GPU (Fractional GPUs)â€æŠ€æœ¯ï¼Œæ™ºèƒ½æ‹¦æˆªå¹¶åˆ†é…ç®—åŠ›ï¼Œå°†æ•´ä½“èµ„æºåˆ©ç”¨ç‡æå‡æ•°å€ã€‚"
                            },
                            {
                                name: "NVIDIA NIM (æ¨ç†å¾®æœåŠ¡)",
                                what: "ç»è¿‡NVIDIAæè‡´ä¼˜åŒ–çš„å®¹å™¨åŒ–AIæ¨¡å‹æ¨ç†å¼•æ“ã€‚",
                                why: "å°†æ•°ç™¾GBçš„å¤§æ¨¡å‹éƒ¨ç½²ä¸ºé«˜æ€§èƒ½APIæä¸ºå¤æ‚ï¼Œæ¶‰åŠåº•å±‚çš„CUDAç‰ˆæœ¬åŒ¹é…ã€TensorRTåŠ é€Ÿç­‰ç¹æ‚æ“ä½œï¼Œè€—æ—¶è€—åŠ›ã€‚",
                                how: "å°†é¢„è®­ç»ƒæ¨¡å‹ã€è¿è¡Œæ—¶å¼•æ“å’Œæ‰€éœ€ä¾èµ–å…¨éƒ¨æ‰“åŒ…ã€‚å¼€å‘è€…åªéœ€è¿è¡Œä¸€è¡Œæ ‡å‡†Dockerå‘½ä»¤ï¼Œå³å¯åœ¨å‡ åˆ†é’Ÿå†…æ‹‰èµ·ä¸€ä¸ªæé«˜æ€§èƒ½çš„ç”Ÿäº§çº§APIä¾›ä¸Šå±‚åº”ç”¨è°ƒç”¨ã€‚"
                            }
                        ]
                    },
                    {
                        id: "layer3",
                        icon: `<rect x="2" y="2" width="20" height="20" rx="2" ry="2"></rect><path d="M7 7h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2z"/>`, // Chip/Compute
                        title: "ç¬¬ä¸‰å±‚ï¼šè®¡ç®—æ¡†æ¶ä¸é€šä¿¡åŠ é€Ÿå±‚ (Compute & Communication Layer)",
                        desc: "æ ¸å¿ƒæµæ°´çº¿â€”â€”ç¡¬ä»¶ä¸ç®—æ³•æ¡†æ¶çš„æ·±åº¦äº¤ç»‡",
                        items: [
                            {
                                name: "PyTorch",
                                what: "ç”±Metaä¸»å¯¼å¼€å‘çš„å½“å‰æœ€ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚",
                                why: "ç ”ç©¶äººå‘˜éœ€è¦ä¸€ä¸ªçµæ´»ã€ç›´è§‚çš„å·¥å…·æ¥å°†å¤æ‚çš„æ•°å­¦å…¬å¼ï¼ˆç¥ç»ç½‘ç»œæ¶æ„ï¼‰è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ä»£ç ã€‚",
                                how: "æä¾›Pythonicçš„æ¥å£å’ŒåŠ¨æ€è®¡ç®—å›¾æœºåˆ¶ã€‚å¼€å‘è€…å¯ä»¥åƒå†™æ™®é€šPythonä»£ç ä¸€æ ·å®šä¹‰ç¥ç»ç½‘ç»œã€è®¡ç®—æŸå¤±å‡½æ•°å¹¶æ§åˆ¶è®­ç»ƒåå‘ä¼ æ’­å¾ªç¯ã€‚"
                            },
                            {
                                name: "CUDA (è®¡ç®—ç»Ÿä¸€è®¾å¤‡æ¶æ„)",
                                what: "NVIDIAæ¨å‡ºçš„è®©GPUæ‰§è¡Œé€šç”¨è®¡ç®—çš„å¹¶è¡Œç¼–ç¨‹å¹³å°ã€‚",
                                why: "CPUæ“…é•¿å¤æ‚çš„å•çº¿ç¨‹é€»è¾‘åˆ¤æ–­ï¼›è€ŒAIçš„æ ¸å¿ƒæ˜¯æµ·é‡ç®€å•çš„çŸ©é˜µä¹˜æ³•ï¼Œéœ€è¦æˆåƒä¸Šä¸‡ä¸ªæ ¸å¿ƒåŒæ—¶å·¥ä½œã€‚CUDAæ¶èµ·äº†è½¯ä»¶æ§åˆ¶GPUçš„æ¡¥æ¢ã€‚",
                                how: "å…è®¸å¼€å‘è€…ä½¿ç”¨C++ç­‰è¯­è¨€ç¼–å†™â€œå†…æ ¸(Kernel)â€ç¨‹åºï¼Œç›´æ¥æŒ‡æŒ¥GPUå†…éƒ¨æµ·é‡çš„æµå¤šå¤„ç†å™¨(SM)åŒæ—¶å¯¹æµ·é‡æ•°æ®è¿›è¡Œå¹¶è¡Œæ•°å­¦è¿ç®—ã€‚"
                            },
                            {
                                name: "NCCL (NVIDIAé›†åˆé€šä¿¡åº“)",
                                what: "ä¸“ä¸ºå¤šGPUèŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®åŒæ­¥ä¼˜åŒ–çš„åº•å±‚é€šä¿¡åº“ã€‚",
                                why: "è®­ç»ƒå¤§æ¨¡å‹éœ€è¦æˆç™¾ä¸Šåƒå¼ GPUååŒå·¥ä½œã€‚åœ¨æ¯ä¸€æ­¥è®¡ç®—åï¼ŒGPUä»¬å¿…é¡»ç›¸äº’äº¤æ¢æ›´æ–°çš„å‚æ•°ï¼ˆæ¢¯åº¦ï¼‰ã€‚å¦‚æœé€šä¿¡æ…¢ï¼Œæ‰€æœ‰GPUéƒ½å¾—åœæœºç­‰å¾…ã€‚",
                                how: "æä¾›è¯¸å¦‚ All-Reduceã€All-Gather ç­‰é«˜åº¦ä¼˜åŒ–çš„æ‹“æ‰‘æ„ŸçŸ¥é€šä¿¡ç®—æ³•ã€‚å®ƒèƒ½è‡ªåŠ¨è¯†åˆ«ç¡¬ä»¶æ¶æ„ï¼ˆå¦‚NVLinkæˆ–PCIeï¼‰ï¼Œé€‰æ‹©æœ€ä¼˜è·¯å¾„åœ¨GPUé—´é«˜é€Ÿæ±‡åˆæ•°æ®ã€‚"
                            }
                        ]
                    },
                    {
                        id: "layer4",
                        icon: `<path d="M4 4h16v4H4zm0 6h16v4H4zm0 6h16v4H4zM6 6h2v2H6zm0 6h2v2H6zm0 6h2v2H6z"/>`, // Network/Switch
                        title: "ç¬¬å››å±‚ï¼šé«˜æ€§èƒ½ç½‘ç»œä¸ç¡¬ä»¶åŸºç¡€è®¾æ–½ (Infrastructure & Network Layer)",
                        desc: "ä¼ é€å¸¦ä¸åœ°åŸºâ€”â€”å†³å®šæ•´ä¸ªå·¥å‚äº§èƒ½çš„æ— æŸç‰©ç†åº•åº§",
                        items: [
                            {
                                name: "RDMA (è¿œç¨‹ç›´æ¥å†…å­˜è®¿é—®)",
                                what: "ä¸€ç§å…è®¸è·¨ç½‘ç»œç›´æ¥è¯»å†™è¿œç¨‹æœåŠ¡å™¨å†…å­˜çš„ç¡¬ä»¶æŠ€æœ¯ã€‚",
                                why: "ä¼ ç»Ÿçš„TCP/IPç½‘ç»œä¼ è¾“æ•°æ®æ—¶ï¼Œéœ€è¦ç»è¿‡æ“ä½œç³»ç»Ÿå†…æ ¸å¤šæ¬¡æ‹·è´å’ŒCPUå¤„ç†ï¼Œå»¶è¿Ÿæé«˜ä¸”å ç”¨CPUèµ„æºï¼Œæ— æ³•æ»¡è¶³AIæµ·é‡æ•°æ®çš„ååéœ€æ±‚ã€‚",
                                how: "æ™ºèƒ½ç½‘å¡(NIC)ç›´æ¥åœ¨ç¡¬ä»¶å±‚é¢å¤„ç†ç½‘ç»œå°åŒ…ã€‚ä¸€å°æœåŠ¡å™¨çš„GPUå¯ä»¥ç›´æ¥å°†æ•°æ®â€œå†™å…¥â€åˆ°å¦ä¸€å°æœåŠ¡å™¨çš„GPUå†…å­˜ä¸­ï¼Œå®ç°é›¶æ‹·è´ã€æä½å»¶è¿Ÿå’Œè¶…é«˜å¸¦å®½ã€‚"
                            },
                            {
                                name: "ROCEv2",
                                what: "åŸºäºèåˆä»¥å¤ªç½‘çš„RDMAåè®® (RDMA over Converged Ethernet)ã€‚",
                                why: "åŸç”ŸRDMAæœ€æ—©è·‘åœ¨æ˜‚è´µçš„InfiniBand(IB)ä¸“æœ‰ç½‘ç»œä¸Šã€‚ä¼ä¸šå¸Œæœ›åœ¨é€šç”¨ã€æˆæœ¬æ›´ä½çš„ä»¥å¤ªç½‘æ¶æ„ä¸Šä¹Ÿèƒ½äº«å—RDMAçš„æ€§èƒ½ã€‚",
                                how: "å°†RDMAæŒ‡ä»¤å°è£…åœ¨æ ‡å‡†çš„UDP/IPä»¥å¤ªç½‘æ•°æ®åŒ…ä¸­ï¼Œé…åˆäº¤æ¢æœºçš„æ— æŸç½‘ç»œé…ç½®ï¼ˆå¦‚PFC/ECNæœºåˆ¶ï¼‰ï¼Œä½¿æ ‡å‡†ä»¥å¤ªç½‘ä¹Ÿèƒ½æ”¯æŒAIæ‰€éœ€çš„é«˜é€Ÿç›´æ¥å†…å­˜ä¼ è¾“ã€‚"
                            },
                            {
                                name: "Adaptive Routing & Packet Spraying",
                                what: "ç°ä»£AIäº¤æ¢æœºï¼ˆå¦‚NVIDIA Spectrum-Xï¼‰ä¸­çš„é«˜çº§æµé‡è°ƒåº¦æœºåˆ¶ã€‚",
                                why: "AIé›†ç¾¤çš„æµé‡å¾€å¾€æ˜¯å¤šå¯¹å¤šçš„â€œå¤§è±¡æµâ€ï¼ˆå·¨å¤§çªå‘æµé‡ï¼‰ã€‚ä¼ ç»Ÿè·¯ç”±ä¼šå°†ä¸€ä¸ªæ•°æ®æµç»‘å®šåœ¨ä¸€æ¡æ­»è·¯å¾„ä¸Šï¼Œææ˜“é€ æˆå±€éƒ¨æ‹¥å µå¯¼è‡´å…¨ç½‘é™é€Ÿã€‚",
                                how: "è‡ªé€‚åº”è·¯ç”±(Adaptive Routing)å®æ—¶æ„ŸçŸ¥å…¨ç½‘æ‹¥å¡ï¼›æ•°æ®åŒ…å–·æ´’(Packet Spraying)å°†åŒä¸€ä¸ªæ•°æ®æµæ‹†æ•£æˆå¾®å°çš„åŒ…ï¼Œé€šè¿‡æ‰€æœ‰å¯ç”¨ç‰©ç†è·¯å¾„åŒæ—¶ä¼ è¾“ï¼Œåˆ°è¾¾ç»ˆç‚¹å†ç”±ç½‘å¡é‡ç»„ï¼Œå®ç°100%æ— æ‹¥å¡ååã€‚"
                            },
                            {
                                name: "UEC (è¶…çº§ä»¥å¤ªç½‘è”ç›Ÿæ ‡å‡†)",
                                what: "é¢å‘æœªæ¥AIå’ŒHPCå·¥ä½œè´Ÿè½½ä¼˜åŒ–çš„ä¸‹ä¸€ä»£å¼€æ”¾å¼ç½‘ç»œä¼ è¾“è§„èŒƒã€‚",
                                why: "éšç€åƒäº¿å‚æ•°æ¨¡å‹å’Œç™¾ä¸‡GPUé›†ç¾¤çš„å‡ºç°ï¼Œç°æœ‰çš„ä»¥å¤ªç½‘åè®®åœ¨å¤„ç†å¾®ç§’çº§å°¾éƒ¨å»¶è¿Ÿå’Œæé«˜ç½‘ç»œè¿é€šçŠ¶æ€æ—¶é‡åˆ°ç“¶é¢ˆã€‚",
                                how: "é€šè¿‡è¡Œä¸šè”ç›Ÿå®šä¹‰å…¨æ–°çš„ä¼ è¾“å±‚åè®®å’Œæœºåˆ¶ï¼ˆå¦‚æ›´ç»†ç²’åº¦çš„å¤šè·¯å¾„ä¼ è¾“ã€æ”¹è¿›çš„æ‹¥å¡æ§åˆ¶å’Œæ›´æ™ºèƒ½çš„ç½‘å¡å¸è½½ï¼‰ï¼Œæ—¨åœ¨æ‰“é€ æ¯”ä¼ ç»ŸROCEv2æ›´æè‡´çš„æ— æŸé«˜æ€§èƒ½ä»¥å¤ªç½‘åº•åº§ã€‚"
                            }
                        ]
                    }
                ]
            },
            en: {
                headerTitle: "AI Factory Architecture Landscape",
                headerSubtitle: "Decoding Modern AI Infrastructure: From Hardware to Applications",
                analogyTitle: "ğŸ’¡ Core Metaphor: The Super Modern Intelligence Factory",
                analogyText: "To understand the complex AI ecosystem, imagine a super factory:<br>â€¢ <strong>Data</strong> is the raw material<br>â€¢ <strong>GPUs</strong> are the assembly line workers<br>â€¢ <strong>Network</strong> is the high-speed conveyor belt<br>â€¢ <strong>AI Apps</strong> are the customized final products",
                labels: { what: "What", why: "Why", how: "How" },
                layers: [
                    {
                        id: "layer1",
                        icon: `<path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"/>`,
                        title: "Layer 1: Application & Business Layer",
                        desc: "The factory's delivery window â€” providing direct business value to end users.",
                        items: [
                            {
                                name: "Large Language Models (LLM / Llama 3 / GPT)",
                                what: "Foundation models with tens/hundreds of billions of parameters.",
                                why: "Traditional software uses rigid rules; LLMs understand natural language, enabling complex generalized tasks like reasoning, coding, and generation.",
                                how: "Through pre-training (building neural connections across massive web data) and fine-tuning (aligning with human intent) via the Transformer architecture to predict the next token."
                            },
                            {
                                name: "RAG (Retrieval-Augmented Generation)",
                                what: "An application paradigm combining private enterprise knowledge with LLM capabilities.",
                                why: "LLM knowledge is frozen in time and prone to 'hallucinations'. Enterprises need answers grounded in the latest, absolutely accurate private data.",
                                how: "When queried, the system retrieves relevant documents from a private vector database, then feeds 'Query + Documents' to the LLM to generate an answer strictly based on those facts."
                            },
                            {
                                name: "Agentic AI",
                                what: "AI systems capable of autonomous planning, tool usage, and multi-step decision-making.",
                                why: "Breaks the limitation of LLMs as mere 'chatbots', transforming them into digital workers that execute real-world tasks (booking, DB queries, software operation).",
                                how: "Equips the LLM with a 'Brain' (memory/planner) and 'Hands' (APIs/Tools). The model analyzes steps, executes SQL or web searches autonomously, and synthesizes the final result."
                            }
                        ]
                    },
                    {
                        id: "layer2",
                        icon: `<path d="M12 15c-1.66 0-3-1.34-3-3s1.34-3 3-3 3 1.34 3 3-1.34 3-3 3zm0-8c-2.76 0-5 2.24-5 5s2.24 5 5 5 5-2.24 5-5-2.24-5-5-5zm8.56 3.44c.22-.66.34-1.36.34-2.09 0-3.53-2.61-6.43-6-6.92V.43C19.12.96 22 4.13 22 7.85c0 .92-.17 1.8-.48 2.61l-1.96-1.02zM1.96 11.02C1.74 11.68 1.62 12.38 1.62 13.1c0 3.53 2.61 6.43 6 6.92v1.01c-4.23-.53-7.11-3.7-7.11-7.42 0-.92.17-1.8.48-2.61l1.97 1.02z"/>`,
                        title: "Layer 2: Orchestration & Serving Layer",
                        desc: "Factory floor scheduling â€” efficient compute management and standard services.",
                        items: [
                            {
                                name: "Kubernetes (K8s)",
                                what: "An open-source container orchestration and cluster management OS.",
                                why: "AI pipelines are massive and complex. Managing environments across thousands of nodes manually is disastrous. Automated deployment, scaling, and self-healing are mandatory.",
                                how: "Applications are packaged into containers (lightweight isolated environments). K8s acts as the 'Datacenter OS' to intelligently schedule and monitor them across server nodes."
                            },
                            {
                                name: "NVIDIA Run:ai",
                                what: "An advanced, AI-specific compute scheduler built on top of Kubernetes.",
                                why: "GPUs are costly but often underutilized (idle or monopolized). Enterprises need multiple data science teams to share a compute pool fluidly.",
                                how: "Utilizes dynamic quotas, job queuing, and 'Fractional GPUs' technology to intelligently intercept and allocate compute, multiplying overall hardware utilization."
                            },
                            {
                                name: "NVIDIA NIM (Inference Microservices)",
                                what: "Highly optimized, containerized AI model inference engines by NVIDIA.",
                                why: "Deploying a massive 100GB model as a fast API is complex, involving strict CUDA version matching and TensorRT acceleration compilation.",
                                how: "Packages pre-trained models, runtime engines, and dependencies together. Developers run a single standard Docker command to spin up a production-ready, ultra-fast API in minutes."
                            }
                        ]
                    },
                    {
                        id: "layer3",
                        icon: `<rect x="2" y="2" width="20" height="20" rx="2" ry="2"></rect><path d="M7 7h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2z"/>`,
                        title: "Layer 3: Compute & Communication Layer",
                        desc: "Core assembly line â€” deep integration of hardware and algorithmic frameworks.",
                        items: [
                            {
                                name: "PyTorch",
                                what: "The dominant deep learning framework, primarily developed by Meta.",
                                why: "Researchers need a flexible, intuitive tool to translate complex mathematical formulas (neural architectures) into executable code.",
                                how: "Provides a Pythonic interface with dynamic computation graphs. Developers define neural networks, loss functions, and backpropagation loops intuitively as standard Python code."
                            },
                            {
                                name: "CUDA (Compute Unified Device Architecture)",
                                what: "NVIDIA's parallel computing platform that allows GPUs to execute general-purpose compute.",
                                why: "CPUs excel at complex logic; AI requires massive, simple matrix multiplications simultaneously. CUDA bridges software to GPU hardware.",
                                how: "Allows developers to write 'Kernels' in C++ to directly command thousands of Streaming Multiprocessors (SMs) inside the GPU to perform parallel math operations on massive datasets."
                            },
                            {
                                name: "NCCL (NVIDIA Collective Communication Library)",
                                what: "A low-level library optimized for data synchronization across multi-GPU nodes.",
                                why: "Training huge models requires thousands of GPUs. After each compute step, GPUs must exchange parameter updates (gradients). If communication lags, all GPUs halt and wait.",
                                how: "Provides highly optimized topology-aware algorithms like All-Reduce and All-Gather. It automatically detects hardware (NVLink/PCIe) to route data optimally across GPUs."
                            }
                        ]
                    },
                    {
                        id: "layer4",
                        icon: `<path d="M4 4h16v4H4zm0 6h16v4H4zm0 6h16v4H4zM6 6h2v2H6zm0 6h2v2H6zm0 6h2v2H6z"/>`,
                        title: "Layer 4: Infrastructure & Network Layer",
                        desc: "Conveyor belt & foundation â€” the physical layer dictating total factory throughput.",
                        items: [
                            {
                                name: "RDMA (Remote Direct Memory Access)",
                                what: "Hardware technology allowing direct read/write access to a remote server's memory.",
                                why: "Traditional TCP/IP networks route data through the OS kernel and CPU, causing high latency and CPU overhead, entirely bottlenecking AI throughput.",
                                how: "SmartNICs handle packets at the hardware layer. A GPU in Server A can 'write' directly into the memory of a GPU in Server B, achieving zero-copy, ultra-low latency, and massive bandwidth."
                            },
                            {
                                name: "ROCEv2",
                                what: "RDMA over Converged Ethernet protocol.",
                                why: "Native RDMA initially ran on expensive, proprietary InfiniBand (IB) networks. Enterprises want RDMA performance over standard, cost-effective Ethernet.",
                                how: "Encapsulates RDMA commands within standard UDP/IP Ethernet packets. Paired with lossless switch configurations (PFC/ECN), it enables high-speed direct memory transfers over Ethernet."
                            },
                            {
                                name: "Adaptive Routing & Packet Spraying",
                                what: "Advanced traffic scheduling mechanisms in modern AI switches (e.g., NVIDIA Spectrum-X).",
                                why: "AI clusters generate massive 'Elephant Flows' (huge traffic bursts). Traditional routing binds a flow to a single path, easily causing local congestion that slows the entire network.",
                                how: "Adaptive Routing senses network congestion in real-time; Packet Spraying splits a single flow into tiny packets, transmitting them simultaneously across all available paths, reassembling at the NIC for 100% congestion-free throughput."
                            },
                            {
                                name: "UEC (Ultra Ethernet Consortium)",
                                what: "A next-generation, open networking standard optimized for future AI and HPC workloads.",
                                why: "As trillion-parameter models and massive GPU clusters emerge, existing Ethernet protocols struggle with microsecond tail-latency and extreme connection states.",
                                how: "Defines new transport layer protocols via an industry consortium (e.g., fine-grained multi-pathing, improved congestion control, smarter NIC offloads) to build an ultimate lossless Ethernet foundation beyond traditional ROCEv2."
                            }
                        ]
                    }
                ]
            }
        };

        let currentLang = 'zh';

        function renderContent() {
            const currentData = data[currentLang];
            const labels = currentData.labels;

            // Update Static Texts
            document.querySelectorAll('[data-i18n]').forEach(el => {
                const key = el.getAttribute('data-i18n');
                if (currentData[key]) {
                    el.innerHTML = currentData[key];
                }
            });

            // Update Button
            document.getElementById('langBtnText').innerText = currentLang === 'zh' ? 'EN' : 'ä¸­æ–‡';

            // Render Layers
            const container = document.getElementById('layersContainer');
            container.innerHTML = ''; // Clear existing

            currentData.layers.forEach((layer, index) => {
                // Determine if layer should be open by default (e.g., first layer)
                const isActive = 'active'; // Changed to make all layers active by default
                
                let itemsHtml = '';
                layer.items.forEach(item => {
                    itemsHtml += `
                        <div class="tech-card">
                            <div class="tech-name">${item.name}</div>
                            <div class="golden-circle">
                                <div class="gc-item gc-what">
                                    <span class="gc-label">${labels.what}</span>
                                    <span class="gc-text">${item.what}</span>
                                </div>
                                <div class="gc-item gc-why">
                                    <span class="gc-label">${labels.why}</span>
                                    <span class="gc-text">${item.why}</span>
                                </div>
                                <div class="gc-item gc-how">
                                    <span class="gc-label">${labels.how}</span>
                                    <span class="gc-text">${item.how}</span>
                                </div>
                            </div>
                        </div>
                    `;
                });

                const layerHtml = `
                    <div class="layer ${isActive}" onclick="toggleLayer(this)">
                        <div class="layer-header">
                            <div class="layer-icon">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">${layer.icon}</svg>
                            </div>
                            <div class="layer-title-wrapper">
                                <div class="layer-title">${layer.title}</div>
                                <div class="layer-desc">${layer.desc}</div>
                            </div>
                            <svg class="expand-icon" viewBox="0 0 24 24">
                                <path d="M7.41 8.59L12 13.17l4.59-4.58L18 10l-6 6-6-6 1.41-1.41z"/>
                            </svg>
                        </div>
                        <div class="layer-content" onclick="event.stopPropagation()">
                            ${itemsHtml}
                        </div>
                    </div>
                `;
                container.innerHTML += layerHtml;
            });
        }

        function toggleLayer(element) {
            const isActive = element.classList.contains('active');
            
            // Optional: Close other layers (Accordion style)
            // document.querySelectorAll('.layer').forEach(layer => layer.classList.remove('active'));
            
            if (!isActive) {
                element.classList.add('active');
            } else {
                element.classList.remove('active');
            }
        }

        function toggleLanguage() {
            currentLang = currentLang === 'zh' ? 'en' : 'zh';
            renderContent();
        }

        // Initialize on load
        document.addEventListener('DOMContentLoaded', renderContent);

    </script>
</body>
</html>